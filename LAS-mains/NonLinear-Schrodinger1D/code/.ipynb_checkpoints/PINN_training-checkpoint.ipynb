{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9f1c90-679a-4f66-8e9d-03fdbc19160c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1831944/2571358700.py:222: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.fixed_uniform = torch.tensor(x_t_init, dtype = torch.float32, device=self.device, requires_grad=True)\n",
      "/tmp/ipykernel_1831944/2571358700.py:183: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.XTGrid = torch.tensor(copy.deepcopy(fixed_uniform), dtype=torch.float32, requires_grad=True).to(self.device)\n",
      "/tmp/ipykernel_1831944/2571358700.py:127: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.XTGrid = torch.tensor(copy.deepcopy(fixed_uniform), dtype=torch.float32, requires_grad=True).to(self.device)\n",
      "/tmp/ipykernel_1831944/2571358700.py:434: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  XTGrid = torch.tensor(XTGrid, dtype=torch.float32, requires_grad=True).to(self.device)\n",
      "/tmp/ipykernel_1831944/2571358700.py:439: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  XTGrid = torch.tensor(XTGrid, dtype=torch.float32, requires_grad=True).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Number = 1000\n",
      "\tIC Loss = 0.00020102907728869468\n",
      "\tBC Loss = 0.001457604463212192\n",
      "\tPhysics Loss = 0.3183274567127228\n",
      "\tTraining Loss = 0.33988797664642334\n",
      "\tRelative L2 error (test) = 37.723660469055176\n",
      "Iteration Number = 2000\n",
      "\tIC Loss = 0.0002560029970481992\n",
      "\tBC Loss = 0.002208260353654623\n",
      "\tPhysics Loss = 0.1774761974811554\n",
      "\tTraining Loss = 0.20528475940227509\n",
      "\tRelative L2 error (test) = 30.09047508239746\n",
      "Iteration Number = 3000\n",
      "\tIC Loss = 0.000224392453674227\n",
      "\tBC Loss = 0.001182379201054573\n",
      "\tPhysics Loss = 0.12645861506462097\n",
      "\tTraining Loss = 0.15008023381233215\n",
      "\tRelative L2 error (test) = 24.314555525779724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader \n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "def cal_domain_grad(model, XTGrid, device):\n",
    "        XTGrid = XTGrid.to(device)\n",
    "        UVf = model(XTGrid)\n",
    "        uf, vf = UVf[:, 0], UVf[:, 1]\n",
    "        uf_t = torch.autograd.grad(outputs=uf.to(device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(uf.shape).to(device), \n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,1]\n",
    "        vf_t = torch.autograd.grad(outputs=vf.to(device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(uf.shape).to(device),\n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,1]\n",
    "        uf_x = torch.autograd.grad(outputs=uf.to(device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(uf.shape).to(device),\n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,0]\n",
    "        uf_xx = torch.autograd.grad(outputs=uf_x.to(device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(uf_x.shape).to(device),\n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,0]\n",
    "        vf_x = torch.autograd.grad(outputs=vf.to(device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(vf.shape).to(device),\n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,0]\n",
    "        vf_xx = torch.autograd.grad(outputs=vf_x.to(device), \n",
    "                                    inputs=XTGrid, \n",
    "                                    grad_outputs=torch.ones(vf_x.shape).to(device),\n",
    "                                    create_graph = True,\n",
    "                                    allow_unused=True)[0][:,0]\n",
    "        \n",
    "        loss = (0.5*uf_xx - vf_t + (uf**2 + vf**2)*uf)**2 + (0.5*vf_xx + uf_t + (uf**2 + vf**2)*vf)**2 \n",
    "        loss =  loss.mean()\n",
    "\n",
    "        mean_x, mean_t = torch.autograd.grad(outputs=loss.to(device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(loss.shape).to(device),\n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0].T\n",
    "        grad = torch.concatenate((mean_x.reshape(-1,1), mean_t.reshape(-1,1)), axis = 1)\n",
    "        return grad\n",
    "\n",
    "\n",
    "class RADSampler():\n",
    "    def __init__(self, Nf, device, k, c):    \n",
    "        self.device = device\n",
    "        self.k = k\n",
    "        self.c = c\n",
    "        self.Nf = Nf\n",
    "        self.dense_Nf = Nf*1\n",
    "        \n",
    "    def update(self, model):\n",
    "        \n",
    "        x_new = torch.zeros(self.dense_Nf, 1, dtype = torch.float32, device=self.device).uniform_(-5, 5)\n",
    "        t_new = torch.zeros(self.dense_Nf, 1, dtype = torch.float32, device=self.device).uniform_(0, np.pi/2)\n",
    "        x_t_new = torch.concatenate((x_new,t_new), axis = 1)\n",
    "        \n",
    "        XTGrid = torch.tensor(x_t_new, dtype = torch.float32, device=self.device, requires_grad=True) \n",
    "        XTGrid = XTGrid.to(self.device)\n",
    "        \n",
    "        UVf = model.forward(XTGrid)\n",
    "        uf, vf = UVf[:, 0], UVf[:, 1]\n",
    "        uf_t = torch.autograd.grad(outputs=uf.to(self.device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(uf.shape).to(self.device), \n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,1]\n",
    "        vf_t = torch.autograd.grad(outputs=vf.to(self.device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(uf.shape).to(self.device),\n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,1]\n",
    "        uf_x = torch.autograd.grad(outputs=uf.to(self.device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(uf.shape).to(self.device),\n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,0]\n",
    "        uf_xx = torch.autograd.grad(outputs=uf_x.to(self.device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(uf_x.shape).to(self.device),\n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,0]\n",
    "        vf_x = torch.autograd.grad(outputs=vf.to(self.device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(vf.shape).to(self.device),\n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,0]\n",
    "        vf_xx = torch.autograd.grad(outputs=vf_x.to(self.device), \n",
    "                                    inputs=XTGrid, \n",
    "                                    grad_outputs=torch.ones(vf_x.shape).to(self.device),\n",
    "                                    create_graph = True,\n",
    "                                    allow_unused=True)[0][:,0]\n",
    "    \n",
    "        \n",
    "        err = torch.abs((0.5*uf_xx - vf_t + (uf**2 + vf**2)*uf)**2 + (0.5*vf_xx + uf_t + (uf**2 + vf**2)*vf))\n",
    "        err = (err**self.k)/((err**self.k).mean())+self.c\n",
    "        err_norm = err/(err.sum())\n",
    "        \n",
    "        indice = torch.multinomial(err_norm, self.Nf, replacement = True)\n",
    "        XTGrid = XTGrid[indice]\n",
    "        self.XTGrid = XTGrid\n",
    "        \n",
    "class LASSampler():\n",
    "    def __init__(self, Nf, fixed_uniform, device, L_iter = 1, beta = 0.2, tau = 0.002):\n",
    "        self.Nf = Nf\n",
    "        self.device = device\n",
    "        self.cnt = 0\n",
    "        self.beta = beta\n",
    "        self.tau = tau\n",
    "        self.L_iter = L_iter\n",
    "        self.XTGrid = torch.tensor(copy.deepcopy(fixed_uniform), dtype=torch.float32, requires_grad=True).to(self.device)\n",
    "\n",
    "    def update(self, phy_lf, model):\n",
    "\n",
    "        # x_new = torch.zeros(self.Nf, 1, dtype = torch.float32, device=self.device).uniform_(-5, 5)\n",
    "        # t_new = torch.zeros(self.Nf, 1, dtype = torch.float32, device=self.device).uniform_(0, np.pi/2)\n",
    "        # x_t_new = torch.concatenate((x_new,t_new), axis = 1)\n",
    "        # self.XTGrid = x_t_new\n",
    "\n",
    "        x_data = self.XTGrid\n",
    "        samples = x_data.clone().detach().requires_grad_(True)\n",
    "        \n",
    "        for t in range(1, self.L_iter + 1):\n",
    "            grad = phy_lf(model, samples, self.device)\n",
    "            scaler = torch.sqrt(torch.sum((grad+1e-16)**2, axis = 1)).reshape(-1,1)\n",
    "            grad = grad/scaler\n",
    "            with torch.no_grad():\n",
    "                samples = samples + self.tau * grad + self.beta*torch.sqrt(torch.tensor(2 * self.tau, device=self.device)) * torch.randn(samples.shape, device=self.device)\n",
    "                samples[:, 0] = torch.clamp(samples[:, 0], min=-5, max=5) \n",
    "                samples[:, 1] = torch.clamp(samples[:, 1], min=0, max=np.pi/2)   \n",
    "            samples = samples.clone().detach().requires_grad_(True)\n",
    "        self.XTGrid = samples.detach()\n",
    "\n",
    "class L_INFSampler():\n",
    "    def __init__(self, Nf, device, step_size = 0.05 , n_iter = 20):\n",
    "\n",
    "        self.Nf = Nf\n",
    "        self.device = device\n",
    "        self.step_size = step_size\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def update(self, phy_lf, model):\n",
    "\n",
    "        x_new = torch.zeros(self.Nf, 1, dtype = torch.float32, device=self.device).uniform_(-5, 5)\n",
    "        t_new = torch.zeros(self.Nf, 1, dtype = torch.float32, device=self.device).uniform_(0, np.pi/2)\n",
    "        x_t_new = torch.concatenate((x_new,t_new), axis = 1)\n",
    "        self.XTGrid = x_t_new\n",
    "            \n",
    "        x_data = self.XTGrid\n",
    "        samples = x_data.clone().detach().requires_grad_(True)\n",
    "    \n",
    "        for t in range(1, self.n_iter + 1):\n",
    "            grad = phy_lf(model, samples, self.device)\n",
    "            with torch.no_grad():\n",
    "                samples = samples + self.step_size * torch.sign(grad)\n",
    "                samples[:, 0] = torch.clamp(samples[:, 0], min=-5, max=5)  \n",
    "                samples[:, 1] = torch.clamp(samples[:, 1], min=0, max=np.pi/2)   \n",
    "            samples = samples.clone().detach().requires_grad_(True)\n",
    "        self.XTGrid = samples.detach()        \n",
    "\n",
    "\n",
    "class R3Sampler(nn.Module):\n",
    "    def __init__(self,Nf, fixed_uniform, device):\n",
    "        super(R3Sampler, self).__init__()\n",
    "        self.Nf = Nf\n",
    "        self.device = device\n",
    "        self.XTGrid = torch.tensor(copy.deepcopy(fixed_uniform), dtype=torch.float32, requires_grad=True).to(self.device)\n",
    "    \n",
    "    def update(self, loss_aver, loss_ele):\n",
    "        with torch.no_grad():\n",
    "            cho_i = loss_ele > loss_aver\n",
    "            cho_i = cho_i.to('cpu')\n",
    "            self.XTGrid = self.XTGrid[cho_i].detach()\n",
    "            need_n_sample = self.Nf-self.XTGrid.shape[0]\n",
    "            x_new = torch.zeros(need_n_sample, 1, dtype = torch.float32, device=self.device).uniform_(-5, 5)\n",
    "            t_new = torch.zeros(need_n_sample, 1, dtype = torch.float32, device=self.device).uniform_(0, np.pi/2)\n",
    "            x_t_new = torch.concatenate((x_new,t_new), axis = 1)\n",
    "            self.XTGrid = torch.concatenate((self.XTGrid, x_t_new), axis = 0)\n",
    "            self.XTGrid = torch.tensor(self.XTGrid, dtype = torch.float32, device=self.device, requires_grad=True)\n",
    "    \n",
    "class PINN(nn.Module):\n",
    "    def __init__(self,k , c , t, X_star, u_star, v_star, exact_u, exact_h, space_domain, time_domain, Layers, N0, Nb, Nf, \n",
    "                 Activation = nn.Tanh(), \n",
    "                 model_name = \"PINN.model\", device = 'cpu',\n",
    "                  display_freq = 100, samp = 'fixed' ):\n",
    "        \n",
    "        super(PINN, self).__init__()\n",
    "        \n",
    "        \n",
    "        LBs = [space_domain[0], time_domain[0]]\n",
    "        UBs = [space_domain[1], time_domain[1]]\n",
    "        \n",
    "        self.LBs = torch.tensor(LBs, dtype=torch.float32).to(device)\n",
    "        self.UBs = torch.tensor(UBs, dtype=torch.float32).to(device)\n",
    "        \n",
    "        self.Layers = Layers\n",
    "        self.in_dim  = Layers[0]\n",
    "        self.out_dim = Layers[-1]\n",
    "        self.Activation = Activation\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        x_init = torch.zeros(Nf, 1, dtype = torch.float32, device=self.device).uniform_(-5, 5)\n",
    "        t_init = torch.zeros(Nf, 1, dtype = torch.float32, device=self.device).uniform_(0, np.pi/2)\n",
    "        x_t_init = torch.concatenate((x_init,t_init), axis = 1)\n",
    "        self.fixed_uniform = torch.tensor(x_t_init, dtype = torch.float32, device=self.device, requires_grad=True)\n",
    "        \n",
    "        self.N0 = N0\n",
    "        self.Nb = Nb\n",
    "        self.Nf = Nf\n",
    "        \n",
    "        self.t = t\n",
    "        self.X_star = X_star\n",
    "        self.u_star = u_star\n",
    "        self.exact_u = exact_u\n",
    "        self.v_star = v_star\n",
    "        self.exact_h = exact_h\n",
    "        \n",
    "        self.XT0, self.u0, self.v0  = self.InitialCondition(self.LBs[0], self.UBs[0])\n",
    "        self.XTbL, self.XTbU = self.BoundaryCondition( self.LBs[0], self.UBs[0])\n",
    "        \n",
    "        self.XT0 = self.XT0.to(device)\n",
    "        self.u0 = self.u0.to(device)\n",
    "        self.v0 = self.v0.to(device) \n",
    "        \n",
    "        self.XTbL = self.XTbL.to(device) \n",
    "        self.XTbU = self.XTbU.to(device)\n",
    "        \n",
    "        self._nn = self.build_model()\n",
    "        self._nn.to(self.device)\n",
    "        self.Loss = torch.nn.MSELoss(reduction='mean')\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.display_freq = display_freq\n",
    "        \n",
    "        self.k = k\n",
    "        self.c = c\n",
    "\n",
    "        self.method = samp\n",
    "        \n",
    "        self.r3_sample = R3Sampler(self.Nf, self.fixed_uniform, device)\n",
    "        self.las = LASSampler(self.Nf, fixed_uniform=self.fixed_uniform, device=self.device, L_iter = 1, beta = 0.2, tau=2e-3)\n",
    "        self.l_inf = L_INFSampler(self.Nf, device=self.device, step_size = 0.05 , n_iter = 20)\n",
    "        self.rad = RADSampler(Nf = self.Nf, device=self.device, k = self.k, c=self.c)\n",
    "        \n",
    "    \n",
    "    def build_model(self):\n",
    "        Seq = nn.Sequential()\n",
    "        for ii in range(len(self.Layers)-1):\n",
    "            this_module = nn.Linear(self.Layers[ii], self.Layers[ii+1])\n",
    "            nn.init.xavier_normal_(this_module.weight)\n",
    "            Seq.add_module(\"Linear\" + str(ii), this_module)\n",
    "            if not ii == len(self.Layers)-2:\n",
    "                Seq.add_module(\"Activation\" + str(ii), self.Activation)\n",
    "        return Seq\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        x = x.reshape((-1,self.in_dim))  \n",
    "        return torch.reshape(self._nn.forward(x), (-1, self.out_dim))\n",
    "\n",
    "    def InitialCondition(self,LB, UB):\n",
    "        x = torch.tensor([])\n",
    "\n",
    "        if (type(LB) != type(x)):\n",
    "          LB = torch.tensor(LB).cpu()\n",
    "        else:\n",
    "          LB = LB.cpu()\n",
    "        if (type(UB) != type(x)):\n",
    "          UB = torch.tensor(UB).cpu()\n",
    "        else:\n",
    "          UB = UB.cpu()\n",
    "\n",
    "        indices = (self.X_star[:,0] >= LB) & (self.X_star[:,0] < UB) & (self.X_star[:,1] == 0.)\n",
    "        XT0 = self.X_star[indices]\n",
    "        u0 = self.u_star[indices]\n",
    "        v0 = self.v_star[indices] \n",
    "\n",
    "        return XT0, u0, v0\n",
    "\n",
    "    def BoundaryCondition(self, LB, UB):\n",
    "        x = torch.tensor([])\n",
    "        \n",
    "        if (type(LB) != type(x)):\n",
    "          LB = torch.tensor(LB).cpu()\n",
    "        else:\n",
    "          LB = LB.cpu()\n",
    "        if (type(UB) != type(x)):\n",
    "          UB = torch.tensor(UB).cpu()\n",
    "        else:\n",
    "          UB = UB.cpu()\n",
    "        \n",
    "        tb =  torch.tensor(np.linspace(0, np.pi/2, self.t.shape[0], endpoint=False), dtype = torch.float32)\n",
    "        XTL = torch.cat(( LB*torch.ones((self.t.shape[0],1)), tb.reshape(-1,1)), dim = 1)\n",
    "        XTL.requires_grad_()\n",
    "        XTU = torch.cat(( UB*torch.ones((self.t.shape[0],1)), tb.reshape(-1,1)), dim = 1)\n",
    "        XTU.requires_grad_()\n",
    "        \n",
    "        return  XTL, XTU\n",
    "    \n",
    "    def ICLoss(self):\n",
    "        idx = torch.randint(0, len(self.XT0), (self.N0,))\n",
    "        \n",
    "        XT0 = self.XT0[idx]\n",
    "        u0  = self.u0[idx]\n",
    "        v0 = self.v0[idx]\n",
    "        \n",
    "        UV0_pred = self.forward(XT0)\n",
    "        u0_pred = UV0_pred[:,0].reshape(-1)\n",
    "        v0_pred = UV0_pred[:,1].reshape(-1)\n",
    "        return self.Loss(u0_pred, u0)+self.Loss(v0_pred, v0)\n",
    "\n",
    "    def BCLoss(self):\n",
    "        idx1 = torch.randint(0, len(self.XTbL), (self.Nb//2,))\n",
    "        idx2 = torch.randint(0, len(self.XTbU), (self.Nb//2,))\n",
    "        \n",
    "        UVb_L, UVb_U = self.forward(self.XTbL[idx1]), self.forward(self.XTbU[idx2])\n",
    "        ub_l, vb_l = UVb_L[:, 0], UVb_L[:, 1]\n",
    "        ub_u, vb_u = UVb_U[:, 0], UVb_U[:, 1]\n",
    "        ub_l_x = torch.autograd.grad(outputs=ub_l.to(self.device), \n",
    "                                     inputs=self.XTbL, \n",
    "                                     grad_outputs=torch.ones(ub_l.shape).to(self.device), \n",
    "                                     create_graph = True,\n",
    "                                     allow_unused=True)[0][:,0]\n",
    "    \n",
    "        vb_l_x = torch.autograd.grad(outputs=vb_l.to(self.device), \n",
    "                                     inputs=self.XTbL, \n",
    "                                     grad_outputs=torch.ones(vb_l.shape).to(self.device),\n",
    "                                     create_graph = True,\n",
    "                                     allow_unused=True)[0][:,0]\n",
    "    \n",
    "        ub_u_x = torch.autograd.grad(outputs=ub_u.to(self.device), \n",
    "                                     inputs=self.XTbU, \n",
    "                                     grad_outputs=torch.ones(ub_u.shape).to(self.device), \n",
    "                                     create_graph = True,\n",
    "                                     allow_unused=True)[0][:,0]\n",
    "    \n",
    "        vb_u_x = torch.autograd.grad(outputs=vb_u.to(self.device), \n",
    "                                     inputs=self.XTbU, \n",
    "                                     grad_outputs=torch.ones(vb_u.shape).to(self.device), \n",
    "                                     create_graph = True,\n",
    "                                     allow_unused=True)[0][:,0]                    \n",
    "        return self.Loss(ub_l, ub_u) + self.Loss(vb_l, vb_u) + \\\n",
    "               self.Loss(ub_l_x, ub_u_x) + self.Loss(vb_l_x, vb_u_x)\n",
    "    \n",
    "    def PhysicsLoss(self, XTGrid):\n",
    "        XTGrid = XTGrid.to(self.device)\n",
    "        UVf = self.forward(XTGrid)\n",
    "        uf, vf = UVf[:, 0], UVf[:, 1]\n",
    "        uf_t = torch.autograd.grad(outputs=uf.to(self.device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(uf.shape).to(self.device), \n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,1]\n",
    "        vf_t = torch.autograd.grad(outputs=vf.to(self.device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(uf.shape).to(self.device),\n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,1]\n",
    "        uf_x = torch.autograd.grad(outputs=uf.to(self.device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(uf.shape).to(self.device),\n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,0]\n",
    "        uf_xx = torch.autograd.grad(outputs=uf_x.to(self.device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(uf_x.shape).to(self.device),\n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,0]\n",
    "        vf_x = torch.autograd.grad(outputs=vf.to(self.device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(vf.shape).to(self.device),\n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0][:,0]\n",
    "        vf_xx = torch.autograd.grad(outputs=vf_x.to(self.device), \n",
    "                                    inputs=XTGrid, \n",
    "                                    grad_outputs=torch.ones(vf_x.shape).to(self.device),\n",
    "                                    create_graph = True,\n",
    "                                    allow_unused=True)[0][:,0]\n",
    "        \n",
    "        loss2 = (0.5*uf_xx - vf_t + (uf**2 + vf**2)*uf)**2 + (0.5*vf_xx + uf_t + (uf**2 + vf**2)*vf)**2 \n",
    "        loss1 =  loss2.mean()\n",
    "        \n",
    "        \n",
    "        return loss1, loss2 \n",
    "    \n",
    "\n",
    "    def Train(self, n_iters, weights=(1.0,1.0,1.0)):\n",
    "        params = list(self.parameters())\n",
    "        optimizer = optim.Adam(params, lr=1e-3)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5000, gamma=0.9, last_epoch=-1)\n",
    "        min_loss = 999999.0\n",
    "        Training_Losses = [-10]*n_iters\n",
    "        Test_Losses = []\n",
    "        rel_error = [-10]*(1+n_iters//1000)\n",
    "        \n",
    "        for jj in range(n_iters):\n",
    "            Total_ICLoss = torch.tensor(0.0, dtype = torch.float32, device=self.device, requires_grad = True)\n",
    "            Total_BCLoss = torch.tensor(0.0, dtype = torch.float32, device=self.device, requires_grad = True)\n",
    "            Total_PhysicsLoss = torch.tensor(0.0, dtype = torch.float32, device=self.device, requires_grad = True)\n",
    "            \n",
    "            Total_ICLoss = Total_ICLoss + self.ICLoss()\n",
    "            Total_BCLoss = Total_BCLoss + self.BCLoss()\n",
    "            \n",
    "            if self.method =='r3':\n",
    "                if jj == 0:\n",
    "                    XTGrid = self.r3_sample.XTGrid\n",
    "                    XTGrid = torch.tensor(XTGrid, dtype = torch.float32, device=self.device, requires_grad=True) \n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        self.r3_sample.update(loss1, loss2)\n",
    "                        XTGrid = self.r3_sample.XTGrid\n",
    "                        XTGrid = torch.tensor(XTGrid, dtype = torch.float32, device=self.device, requires_grad=True) \n",
    "                        \n",
    "            elif self.method == 'las':\n",
    "                if jj == 0:\n",
    "                    XTGrid = self.las.XTGrid\n",
    "                    XTGrid = torch.tensor(XTGrid, dtype=torch.float32, requires_grad=True).to(self.device)\n",
    "                else:\n",
    "                    if self.las.cnt % 1 == 0:# 4,6,8,10 cnt = 4, \n",
    "                        self.las.update(cal_domain_grad, self._nn)\n",
    "                    XTGrid = self.las.XTGrid\n",
    "                    XTGrid = torch.tensor(XTGrid, dtype=torch.float32, requires_grad=True).to(self.device)\n",
    "                self.las.cnt += 1\n",
    "            \n",
    "            elif self.method =='l_inf':\n",
    "                    self.l_inf.update(cal_domain_grad, self._nn)\n",
    "                    XTGrid = self.l_inf.XTGrid\n",
    "                    XTGrid = torch.tensor(XTGrid, dtype=torch.float32, requires_grad=True).to(self.device)\n",
    "                \n",
    "            elif self.method =='rad':\n",
    "                    self.rad.update(self._nn)\n",
    "                    XTGrid = self.rad.XTGrid\n",
    "                    XTGrid = torch.tensor(XTGrid, dtype=torch.float32, requires_grad=True).to(self.device)   \n",
    "            \n",
    "            elif self.method =='fixed':\n",
    "                    XTGrid = torch.tensor(self.fixed_uniform, dtype = torch.float32, device=self.device, requires_grad=True) \n",
    "            \n",
    "            elif self.method =='random-r':\n",
    "                    x_new = torch.zeros(self.Nf, 1, dtype = torch.float32, device=self.device).uniform_(-1, 1)\n",
    "                    t_new = torch.zeros(self.Nf, 1, dtype = torch.float32, device=self.device).uniform_(0, 1)\n",
    "                    x_t_new = torch.concatenate((x_new,t_new), axis = 1)\n",
    "                    XTGrid = torch.tensor(x_t_new, dtype = torch.float32, device=self.device, requires_grad=True) \n",
    "                \n",
    "            optimizer.zero_grad()    \n",
    "            loss1, loss2 = self.PhysicsLoss(XTGrid) # For r3 method, loss2 contains element-wise errors\n",
    "            \n",
    "            Total_PhysicsLoss = Total_PhysicsLoss + loss1\n",
    "            Total_Loss = weights[0]*Total_ICLoss + weights[1]*Total_BCLoss\\\n",
    "                        + weights[2]*Total_PhysicsLoss \n",
    "            \n",
    "            Total_Loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            if Total_Loss < min_loss:\n",
    "                torch.save(self._nn.state_dict(), \"../models/\"+self.method+'_'+str(len(self.Layers)-2)+'_'+str(self.Nf)+'.pt')\n",
    "                min_loss = float(Total_Loss)\n",
    "                    \n",
    "            Training_Losses[jj] = float(Total_Loss)\n",
    "            \n",
    "            if (jj+1) % self.display_freq == 0:\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.forward(self.X_star)\n",
    "                    outputs_u  = outputs[:,0]\n",
    "                    outputs_v  = outputs[:,1]\n",
    "                    outputs_h = torch.sqrt(outputs_u**2 + outputs_v**2)\n",
    "                    outputs = outputs_h.reshape(201,256)\n",
    "                    re = np.linalg.norm(self.exact_h.T.cpu()-outputs.cpu().detach()) / np.linalg.norm(self.exact_h.T.cpu().detach())\n",
    "                    rel_error[int((jj+1)/1000)] = float(re*100)\n",
    "                print(\"Iteration Number = {}\".format(jj+1))\n",
    "                print(\"\\tIC Loss = {}\".format(float(Total_ICLoss)))\n",
    "                print(\"\\tBC Loss = {}\".format(float(Total_BCLoss)))\n",
    "                print(\"\\tPhysics Loss = {}\".format(float(Total_PhysicsLoss)))\n",
    "                print(\"\\tTraining Loss = {}\".format(float(Total_Loss)))\n",
    "                print(\"\\tRelative L2 error (test) = {}\".format(float(re*100)))\n",
    "                # torch.save(XTGrid, \"../models/\"+self.method +'/'+str(self.Nf)+\"_grid_\"+str(jj+1))\n",
    "                # torch.save(self.exact_h.T.cpu()-outputs.cpu().detach(), \"../models/\"+self.method +'/'+str(self.Nf)+\"_error_\"+str(jj+1))\n",
    "\n",
    "        return Training_Losses, rel_error\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "                \n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--nodes', type=int, default = 128, help='The number of nodes per hidden layer in the neural network')\n",
    "        parser.add_argument('--layers', type=int, default = 8, help='The number of hidden layers in the neural network')\n",
    "        parser.add_argument('--N0', type=int, default = 100, help='The number of points to use on the initial condition')\n",
    "        parser.add_argument('--Nb', type=int, default = 100, help='The number of points to use on the boundary condition')\n",
    "        parser.add_argument('--Nf', type=int, default = 1000, help='The number of collocation points to use')\n",
    "        parser.add_argument('--epochs', type=int, default = 200000, help='The number of epochs to train the neural network')\n",
    "        parser.add_argument('--method', type=str, default='las', help='Sampling method') # fixed, random-r, rad, r3, l_inf, las \n",
    "        parser.add_argument('--model-name', type=str, default='PINN_model', help='File name to save the model')\n",
    "        parser.add_argument('--display-freq', type=int, default=1000, help='How often to display loss information')\n",
    "        parser.add_argument('-f')\n",
    "        args = parser.parse_args()\n",
    "\n",
    "        data = io.loadmat(\"../data/NLS.mat\")\n",
    "        t = torch.tensor(data['tt'], dtype = torch.float32).reshape(-1)\n",
    "        x = torch.tensor(data['x'], dtype = torch.float32).reshape(-1)\n",
    "        Exact = data['uu']\n",
    "        Exact_u = torch.tensor(np.real(Exact), dtype = torch.float32)\n",
    "        Exact_v = torch.tensor(np.imag(Exact), dtype = torch.float32)\n",
    "        Exact_h = torch.sqrt(Exact_u**2 + Exact_v**2)\n",
    "        X, T = np.meshgrid(x,t)\n",
    "        X_star = torch.tensor(np.hstack((X.flatten()[:,None], T.flatten()[:,None])), dtype = torch.float32)\n",
    "        u_star = torch.flatten(torch.transpose(Exact_u,0,1))\n",
    "        v_star = torch.flatten(torch.transpose(Exact_v,0,1))\n",
    "        h_star = torch.flatten(torch.transpose(Exact_h,0,1))\n",
    "        \n",
    "        if not os.path.exists(\"../models/\"):\n",
    "            os.mkdir(\"../models/\")\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        NHiddenLayers = args.layers\n",
    "        \n",
    "        boundaries = [-5, 5]\n",
    "        t_domain = [0., np.pi/2]\n",
    "        \n",
    "        Layers = [2] + [args.nodes]*NHiddenLayers + [2]\n",
    "        Activation = nn.Tanh()\n",
    "\n",
    "        k = 1\n",
    "        c = 1\n",
    "\n",
    "        repeat = [0, 1, 2, 3, 4]\n",
    "        for i in repeat:\n",
    "            pinn = PINN(  k = k,\n",
    "                          c = c,\n",
    "                          t= t,\n",
    "                          X_star = X_star,\n",
    "                          u_star = u_star,\n",
    "                          v_star = v_star,\n",
    "                          exact_u = Exact_u,\n",
    "                          exact_h = Exact_h,\n",
    "                          space_domain = boundaries,\n",
    "                          time_domain = t_domain,\n",
    "                          Layers = Layers,\n",
    "                          N0 = args.N0,\n",
    "                          Nb = args.Nb,\n",
    "                          Nf = args.Nf,\n",
    "                          Activation = Activation,\n",
    "                          device = device,\n",
    "                          model_name = \"../models/\" + args.model_name + \".model_\"+args.method+'_'+str(args.layers)+'_'+str(args.Nf)+'_'+str(i),\n",
    "                          display_freq = args.display_freq, samp = args.method )\n",
    "\n",
    "            Losses_train, Losses_rel_l2 = pinn.Train(args.epochs, weights = (100, 1, 1)) # initial, boundary, residual\n",
    "\n",
    "            torch.save(Losses_train, \"../models/\" + args.model_name + \".loss_\"+args.method+'_'+str(args.layers)+'_'+str(args.Nf)+'_'+str(i))\n",
    "            torch.save(Losses_rel_l2, \"../models/\" + args.model_name + \".rel_l2_\"+args.method+'_'+str(args.layers)+'_'+str(args.Nf)+'_'+str(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
