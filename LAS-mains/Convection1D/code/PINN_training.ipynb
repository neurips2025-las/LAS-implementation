{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f106b98-72bc-4e45-917a-ce370715a8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1046317/2181283442.py:168: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.fixed_uniform = torch.tensor(x_t_init, dtype = torch.float32, device=self.device, requires_grad=True)\n",
      "/tmp/ipykernel_1046317/2181283442.py:129: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.XTGrid = torch.tensor(copy.deepcopy(fixed_uniform), dtype=torch.float32, requires_grad=True).to(self.device)\n",
      "/tmp/ipykernel_1046317/2181283442.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.XTGrid = torch.tensor(copy.deepcopy(fixed_uniform), dtype=torch.float32, requires_grad=True).to(self.device)\n",
      "/tmp/ipykernel_1046317/2181283442.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  XTGrid = torch.tensor(x_t_new, dtype = torch.float32, device=self.device, requires_grad=True)\n",
      "/tmp/ipykernel_1046317/2181283442.py:333: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  XTGrid = torch.tensor(XTGrid, dtype=torch.float32, requires_grad=True).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Number = 1000\n",
      "\tIC Loss = 0.0027005900628864765\n",
      "\tBC Loss = 0.018741225823760033\n",
      "\tPhysics Loss = 0.6016621589660645\n",
      "\tTraining Loss = 2.7458438873291016\n",
      "\tRelative L2 error (test) = 94.16853785514832\n",
      "Iteration Number = 2000\n",
      "\tIC Loss = 0.0016747827176004648\n",
      "\tBC Loss = 0.011206778697669506\n",
      "\tPhysics Loss = 0.4584014117717743\n",
      "\tTraining Loss = 1.746557593345642\n",
      "\tRelative L2 error (test) = 90.92063307762146\n",
      "Iteration Number = 3000\n",
      "\tIC Loss = 0.000916476477868855\n",
      "\tBC Loss = 0.007856812328100204\n",
      "\tPhysics Loss = 0.5130242705345154\n",
      "\tTraining Loss = 1.3903532028198242\n",
      "\tRelative L2 error (test) = 88.36347460746765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader \n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "def cal_domain_grad(model, XTGrid, device):\n",
    "    XTGrid = XTGrid.to(device)\n",
    "    uf = model.forward(XTGrid)[:,0]\n",
    "    uf_x, uf_t = torch.autograd.grad(outputs=uf.to(device), \n",
    "                               inputs=XTGrid, \n",
    "                               grad_outputs=torch.ones(uf.shape).to(device), \n",
    "                               create_graph = True,\n",
    "                               allow_unused=True)[0].T\n",
    "    \n",
    "    loss =  (uf_t + 50*uf_x)**2\n",
    "\n",
    "    mean_x, mean_t = torch.autograd.grad(outputs=loss.to(device), \n",
    "                               inputs=XTGrid, \n",
    "                               grad_outputs=torch.ones(loss.shape).to(device),\n",
    "                               create_graph = True,\n",
    "                               allow_unused=True)[0].T\n",
    "    grad = torch.concatenate((mean_x.reshape(-1,1), mean_t.reshape(-1,1)), axis = 1)\n",
    "    return grad\n",
    "\n",
    "\n",
    "class RADSampler():\n",
    "    def __init__(self, Nf, device, k, c):    \n",
    "        self.device = device\n",
    "        self.k = k\n",
    "        self.c = c\n",
    "        self.Nf = Nf\n",
    "        self.dense_Nf = Nf*1\n",
    "        \n",
    "    def update(self, model):\n",
    "        \n",
    "        x_new = torch.zeros(self.dense_Nf, 1, dtype = torch.float32, device=self.device).uniform_(0, 2*torch.pi)\n",
    "        t_new = torch.zeros(self.dense_Nf, 1, dtype = torch.float32, device=self.device).uniform_(0, 1)\n",
    "        x_t_new = torch.concatenate((x_new,t_new), axis = 1)\n",
    "        \n",
    "        XTGrid = torch.tensor(x_t_new, dtype = torch.float32, device=self.device, requires_grad=True) \n",
    "        XTGrid = XTGrid.to(self.device)\n",
    "        \n",
    "        uf = model.forward(XTGrid)[:,0]\n",
    "        uf_x, uf_t = torch.autograd.grad(outputs=uf.to(self.device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(uf.shape).to(self.device), \n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0].T\n",
    "        \n",
    "        err = torch.abs((uf_t + 50*uf_x))\n",
    "        err = (err**self.k)/((err**self.k).mean())+self.c\n",
    "        err_norm = err/(err.sum())\n",
    "        \n",
    "        indice = torch.multinomial(err_norm, self.Nf, replacement = True)\n",
    "        XTGrid = XTGrid[indice]\n",
    "        self.XTGrid = XTGrid\n",
    "        \n",
    "class LASSampler():\n",
    "    def __init__(self, Nf, fixed_uniform, device, L_iter = 1, beta = 0.2, tau = 0.002):\n",
    "        self.Nf = Nf\n",
    "        self.device = device\n",
    "        self.cnt = 0\n",
    "        self.beta = beta\n",
    "        self.tau = tau\n",
    "        self.L_iter = L_iter\n",
    "        self.XTGrid = torch.tensor(copy.deepcopy(fixed_uniform), dtype=torch.float32, requires_grad=True).to(self.device)\n",
    "\n",
    "    def update(self, phy_lf, model):\n",
    "\n",
    "        # x_new = torch.zeros(self.Nf, 1, dtype = torch.float32, device=self.device).uniform_(-1, 1)\n",
    "        # t_new = torch.zeros(self.Nf, 1, dtype = torch.float32, device=self.device).uniform_(0, 1)\n",
    "        # x_t_new = torch.concatenate((x_new,t_new), axis = 1)\n",
    "        # self.XTGrid = x_t_new\n",
    "\n",
    "        x_data = self.XTGrid\n",
    "        samples = x_data.clone().detach().requires_grad_(True)\n",
    "        \n",
    "        for t in range(1, self.L_iter + 1):\n",
    "            grad = phy_lf(model, samples, self.device)\n",
    "            scaler = torch.sqrt(torch.sum((grad+1e-16)**2, axis = 1)).reshape(-1,1)\n",
    "            grad = grad/scaler\n",
    "            with torch.no_grad():\n",
    "                samples = samples + self.tau * grad + self.beta*torch.sqrt(torch.tensor(2 * self.tau, device=self.device)) * torch.randn(samples.shape, device=self.device)\n",
    "                samples[:, 0] = torch.clamp(samples[:, 0], min=0, max=2*torch.pi) \n",
    "                samples[:, 1] = torch.clamp(samples[:, 1], min=0, max=1)   \n",
    "            samples = samples.clone().detach().requires_grad_(True)\n",
    "        self.XTGrid = samples.detach()\n",
    "\n",
    "class L_INFSampler():\n",
    "    def __init__(self, Nf, device, step_size = 0.05 , n_iter = 20):\n",
    "\n",
    "        self.Nf = Nf\n",
    "        self.device = device\n",
    "        self.step_size = step_size\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def update(self, phy_lf, model):\n",
    "\n",
    "        x_new = torch.zeros(self.Nf, 1, dtype = torch.float32, device=self.device).uniform_(0, 2*torch.pi)\n",
    "        t_new = torch.zeros(self.Nf, 1, dtype = torch.float32, device=self.device).uniform_(0, 1)\n",
    "        x_t_new = torch.concatenate((x_new,t_new), axis = 1)\n",
    "        self.XTGrid = x_t_new\n",
    "            \n",
    "        x_data = self.XTGrid\n",
    "        samples = x_data.clone().detach().requires_grad_(True)\n",
    "    \n",
    "        for t in range(1, self.n_iter + 1):\n",
    "            grad = phy_lf(model, samples, self.device)\n",
    "            with torch.no_grad():\n",
    "                samples = samples + self.step_size * torch.sign(grad)\n",
    "                samples[:, 0] = torch.clamp(samples[:, 0], min=0, max=2*torch.pi)  \n",
    "                samples[:, 1] = torch.clamp(samples[:, 1], min=0, max=1)   \n",
    "            samples = samples.clone().detach().requires_grad_(True)\n",
    "        self.XTGrid = samples.detach()        \n",
    "\n",
    "\n",
    "class R3Sampler(nn.Module):\n",
    "    def __init__(self,Nf, fixed_uniform, device):\n",
    "        super(R3Sampler, self).__init__()\n",
    "        self.Nf = Nf\n",
    "        self.device = device\n",
    "        self.XTGrid = torch.tensor(copy.deepcopy(fixed_uniform), dtype=torch.float32, requires_grad=True).to(self.device)\n",
    "    \n",
    "    def update(self, loss_aver, loss_ele):\n",
    "        with torch.no_grad():\n",
    "            cho_i = loss_ele > loss_aver\n",
    "            cho_i = cho_i.to('cpu')\n",
    "            self.XTGrid = self.XTGrid[cho_i].detach()\n",
    "            need_n_sample = self.Nf-self.XTGrid.shape[0]\n",
    "            x_new = torch.zeros(need_n_sample, 1, dtype = torch.float32, device=self.device).uniform_(0, 2*torch.pi)\n",
    "            t_new = torch.zeros(need_n_sample, 1, dtype = torch.float32, device=self.device).uniform_(0, 1)\n",
    "            x_t_new = torch.concatenate((x_new,t_new), axis = 1)\n",
    "            self.XTGrid = torch.concatenate((self.XTGrid, x_t_new), axis = 0)\n",
    "            self.XTGrid = torch.tensor(self.XTGrid, dtype = torch.float32, device=self.device, requires_grad=True)\n",
    "    \n",
    "class PINN(nn.Module):\n",
    "    def __init__(self,k , c , t, X_star, u_star, exact_u, space_domain, time_domain, Layers, N0, Nb, Nf, \n",
    "                 Activation = nn.Tanh(), \n",
    "                 model_name = \"PINN.model\", device = 'cpu',\n",
    "                  display_freq = 100, samp = 'fixed' ):\n",
    "        \n",
    "        super(PINN, self).__init__()\n",
    "        \n",
    "        \n",
    "        LBs = [space_domain[0], time_domain[0]]\n",
    "        UBs = [space_domain[1], time_domain[1]]\n",
    "        \n",
    "        self.LBs = torch.tensor(LBs, dtype=torch.float32).to(device)\n",
    "        self.UBs = torch.tensor(UBs, dtype=torch.float32).to(device)\n",
    "        \n",
    "        self.Layers = Layers\n",
    "        self.in_dim  = Layers[0]\n",
    "        self.out_dim = Layers[-1]\n",
    "        self.Activation = Activation\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        x_init = torch.zeros(Nf, 1, dtype = torch.float32, device=self.device).uniform_(0, 2*torch.pi)\n",
    "        t_init = torch.zeros(Nf, 1, dtype = torch.float32, device=self.device).uniform_(0, 1)\n",
    "        x_t_init = torch.concatenate((x_init,t_init), axis = 1)\n",
    "        self.fixed_uniform = torch.tensor(x_t_init, dtype = torch.float32, device=self.device, requires_grad=True)\n",
    "        \n",
    "        self.N0 = N0\n",
    "        self.Nb = Nb\n",
    "        self.Nf = Nf\n",
    "        \n",
    "        self.t = t\n",
    "        self.X_star = X_star\n",
    "        self.u_star = u_star\n",
    "        self.exact_u = exact_u\n",
    "        \n",
    "        self.XT0, self.u0  = self.InitialCondition(self.LBs[0], self.UBs[0])\n",
    "        self.XTbL, self.XTbU = self.BoundaryCondition( self.LBs[0], self.UBs[0])\n",
    "        \n",
    "        self.XT0 = self.XT0.to(device)\n",
    "        self.u0 = self.u0.to(device) \n",
    "        \n",
    "        self.XTbL = self.XTbL.to(device) \n",
    "        self.XTbU = self.XTbU.to(device)\n",
    "        \n",
    "        self._nn = self.build_model()\n",
    "        self._nn.to(self.device)\n",
    "        self.Loss = torch.nn.MSELoss(reduction='mean')\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.display_freq = display_freq\n",
    "        \n",
    "        self.k = k\n",
    "        self.c = c\n",
    "\n",
    "        self.method = samp\n",
    "        \n",
    "        self.r3_sample = R3Sampler(self.Nf, self.fixed_uniform, device)\n",
    "        self.las = LASSampler(self.Nf, fixed_uniform=self.fixed_uniform, device=self.device, L_iter = 1, beta = 0.2, tau=2e-3)\n",
    "        self.l_inf = L_INFSampler(self.Nf, device=self.device, step_size = 0.05 , n_iter = 20)\n",
    "        self.rad = RADSampler(Nf = self.Nf, device=self.device, k = self.k, c=self.c)\n",
    "        \n",
    "    \n",
    "    def build_model(self):\n",
    "        Seq = nn.Sequential()\n",
    "        for ii in range(len(self.Layers)-1):\n",
    "            this_module = nn.Linear(self.Layers[ii], self.Layers[ii+1])\n",
    "            nn.init.xavier_normal_(this_module.weight)\n",
    "            Seq.add_module(\"Linear\" + str(ii), this_module)\n",
    "            if not ii == len(self.Layers)-2:\n",
    "                Seq.add_module(\"Activation\" + str(ii), self.Activation)\n",
    "        return Seq\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        x = x.reshape((-1,self.in_dim))  \n",
    "        return torch.reshape(self._nn.forward(x), (-1, self.out_dim))\n",
    "\n",
    "    def InitialCondition(self,LB, UB):\n",
    "        x = torch.tensor([])\n",
    "\n",
    "        if (type(LB) != type(x)):\n",
    "          LB = torch.tensor(LB).cpu()\n",
    "        else:\n",
    "          LB = LB.cpu()\n",
    "        if (type(UB) != type(x)):\n",
    "          UB = torch.tensor(UB).cpu()\n",
    "        else:\n",
    "          UB = UB.cpu()\n",
    "\n",
    "        indices = (self.X_star[:,0] >= LB) & (self.X_star[:,0] < UB) & (self.X_star[:,1] == 0.)\n",
    "        XT0 = self.X_star[indices]\n",
    "        u0 = self.u_star[indices]\n",
    "\n",
    "        return XT0, u0\n",
    "\n",
    "    def BoundaryCondition(self, LB, UB):\n",
    "        x = torch.tensor([])\n",
    "        \n",
    "        if (type(LB) != type(x)):\n",
    "          LB = torch.tensor(LB).cpu()\n",
    "        else:\n",
    "          LB = LB.cpu()\n",
    "        if (type(UB) != type(x)):\n",
    "          UB = torch.tensor(UB).cpu()\n",
    "        else:\n",
    "          UB = UB.cpu()\n",
    "        \n",
    "        tb =  torch.tensor(np.linspace(0, 1, self.t.shape[0], endpoint=False), dtype = torch.float32)\n",
    "        XTL = torch.cat(( LB*torch.ones((self.t.shape[0],1)), tb.reshape(-1,1)), dim = 1)\n",
    "        XTL.requires_grad_()\n",
    "        XTU = torch.cat(( UB*torch.ones((self.t.shape[0],1)), tb.reshape(-1,1)), dim = 1)\n",
    "        XTU.requires_grad_()\n",
    "        \n",
    "        return  XTL, XTU\n",
    "    \n",
    "    def ICLoss(self):\n",
    "        XT0 = self.XT0\n",
    "        u0  = self.u0\n",
    "        UV0_pred = self.forward(XT0)\n",
    "        u0_pred = UV0_pred[:,0].reshape(-1)\n",
    "        return self.Loss(u0_pred, u0)\n",
    "\n",
    "    def BCLoss(self):\n",
    "        ub_l = self.forward(self.XTbL)\n",
    "        ub_u = self.forward(self.XTbU)\n",
    "        \n",
    "        return torch.mean((ub_l-ub_u)**2)\n",
    "    \n",
    "    def PhysicsLoss(self, XTGrid):\n",
    "        XTGrid = XTGrid.to(self.device)\n",
    "        uf = self.forward(XTGrid)[:,0]\n",
    "        uf_x, uf_t = torch.autograd.grad(outputs=uf.to(self.device), \n",
    "                                   inputs=XTGrid, \n",
    "                                   grad_outputs=torch.ones(uf.shape).to(self.device), \n",
    "                                   create_graph = True,\n",
    "                                   allow_unused=True)[0].T\n",
    "        \n",
    "        loss2 =  (uf_t + 50*uf_x)**2\n",
    "        loss1 = loss2.mean()\n",
    "        \n",
    "        return loss1, loss2 \n",
    "    \n",
    "\n",
    "    def Train(self, n_iters, weights=(1.0,1.0,1.0)):\n",
    "        params = list(self.parameters())\n",
    "        optimizer = optim.Adam(params, lr=1e-3)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5000, gamma=0.9, last_epoch=-1)\n",
    "        min_loss = 999999.0\n",
    "        Training_Losses = [-10]*n_iters\n",
    "        Test_Losses = []\n",
    "        rel_error = [-10]*(1+n_iters//1000)\n",
    "        \n",
    "        for jj in range(n_iters):\n",
    "            Total_ICLoss = torch.tensor(0.0, dtype = torch.float32, device=self.device, requires_grad = True)\n",
    "            Total_BCLoss = torch.tensor(0.0, dtype = torch.float32, device=self.device, requires_grad = True)\n",
    "            Total_PhysicsLoss = torch.tensor(0.0, dtype = torch.float32, device=self.device, requires_grad = True)\n",
    "            \n",
    "            Total_ICLoss = Total_ICLoss + self.ICLoss()\n",
    "            Total_BCLoss = Total_BCLoss + self.BCLoss()\n",
    "            \n",
    "            if self.method =='r3':\n",
    "                if jj == 0:\n",
    "                    XTGrid = self.r3_sample.XTGrid\n",
    "                    XTGrid = torch.tensor(XTGrid, dtype = torch.float32, device=self.device, requires_grad=True) \n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        self.r3_sample.update(loss1, loss2)\n",
    "                        XTGrid = self.r3_sample.XTGrid\n",
    "                        XTGrid = torch.tensor(XTGrid, dtype = torch.float32, device=self.device, requires_grad=True) \n",
    "                        \n",
    "            elif self.method == 'las':\n",
    "                if jj == 0:\n",
    "                    XTGrid = self.las.XTGrid\n",
    "                    XTGrid = torch.tensor(XTGrid, dtype=torch.float32, requires_grad=True).to(self.device)\n",
    "                else:\n",
    "                    if self.las.cnt % 1 == 0:# 4,6,8,10 cnt = 4, \n",
    "                        self.las.update(cal_domain_grad, self._nn)\n",
    "                    XTGrid = self.las.XTGrid\n",
    "                    XTGrid = torch.tensor(XTGrid, dtype=torch.float32, requires_grad=True).to(self.device)\n",
    "                self.las.cnt += 1\n",
    "            \n",
    "            elif self.method =='l_inf':\n",
    "                    self.l_inf.update(cal_domain_grad, self._nn)\n",
    "                    XTGrid = self.l_inf.XTGrid\n",
    "                    XTGrid = torch.tensor(XTGrid, dtype=torch.float32, requires_grad=True).to(self.device)\n",
    "                \n",
    "            elif self.method =='rad':\n",
    "                    self.rad.update(self._nn)\n",
    "                    XTGrid = self.rad.XTGrid\n",
    "                    XTGrid = torch.tensor(XTGrid, dtype=torch.float32, requires_grad=True).to(self.device)   \n",
    "            \n",
    "            elif self.method =='fixed':\n",
    "                    XTGrid = torch.tensor(self.fixed_uniform, dtype = torch.float32, device=self.device, requires_grad=True) \n",
    "            \n",
    "            elif self.method =='random-r':\n",
    "                    x_new = torch.zeros(self.Nf, 1, dtype = torch.float32, device=self.device).uniform_(0, 2*torch.pi)\n",
    "                    t_new = torch.zeros(self.Nf, 1, dtype = torch.float32, device=self.device).uniform_(0, 1)\n",
    "                    x_t_new = torch.concatenate((x_new,t_new), axis = 1)\n",
    "                    XTGrid = torch.tensor(x_t_new, dtype = torch.float32, device=self.device, requires_grad=True) \n",
    "                \n",
    "            optimizer.zero_grad()    \n",
    "            loss1, loss2 = self.PhysicsLoss(XTGrid) # For r3 method, loss2 contains element-wise errors\n",
    "            \n",
    "            Total_PhysicsLoss = Total_PhysicsLoss + loss1\n",
    "            Total_Loss = weights[0]*Total_ICLoss + weights[1]*Total_BCLoss\\\n",
    "                        + weights[2]*Total_PhysicsLoss \n",
    "            \n",
    "            Total_Loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            if Total_Loss < min_loss:\n",
    "                torch.save(self._nn.state_dict(), \"../models/\"+self.method+'_'+str(len(self.Layers)-2)+'_'+str(self.Nf)+'.pt')\n",
    "                min_loss = float(Total_Loss)\n",
    "                    \n",
    "            Training_Losses[jj] = float(Total_Loss)\n",
    "            \n",
    "            if (jj+1) % self.display_freq == 0:\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.forward(X_star)\n",
    "                    outputs = outputs.reshape(201,512)\n",
    "                    re = np.linalg.norm(Exact_u.cpu().T-outputs.cpu().detach()) / np.linalg.norm(Exact_u.cpu().detach().T)\n",
    "                    rel_error[int((jj+1)/1000)] = float(re*100)\n",
    "                print(\"Iteration Number = {}\".format(jj+1))\n",
    "                print(\"\\tIC Loss = {}\".format(float(Total_ICLoss)))\n",
    "                print(\"\\tBC Loss = {}\".format(float(Total_BCLoss)))\n",
    "                print(\"\\tPhysics Loss = {}\".format(float(Total_PhysicsLoss)))\n",
    "                print(\"\\tTraining Loss = {}\".format(float(Total_Loss)))\n",
    "                print(\"\\tRelative L2 error (test) = {}\".format(float(re*100)))\n",
    "                # torch.save(XTGrid, \"../models/\"+self.method +'/'+str(self.Nf)+\"_grid_\"+str(jj+1))\n",
    "                # torch.save(Exact_u.cpu().T-outputs.cpu().detach(), \"../models/\"+self.method +'/'+str(self.Nf)+\"_error_\"+str(jj+1))\n",
    "\n",
    "        return Training_Losses, rel_error\n",
    "\n",
    "def function(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "                \n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--nodes', type=int, default = 128, help='The number of nodes per hidden layer in the neural network')\n",
    "        parser.add_argument('--layers', type=int, default = 8, help='The number of hidden layers in the neural network')\n",
    "        parser.add_argument('--N0', type=int, default = 100, help='The number of points to use on the initial condition')\n",
    "        parser.add_argument('--Nb', type=int, default = 100, help='The number of points to use on the boundary condition')\n",
    "        parser.add_argument('--Nf', type=int, default = 1000, help='The number of collocation points to use')\n",
    "        parser.add_argument('--epochs', type=int, default = 200000, help='The number of epochs to train the neural network')\n",
    "        parser.add_argument('--method', type=str, default='rad', help='Sampling method') # fixed, random-r, rad, r3, l_inf, las \n",
    "        parser.add_argument('--model-name', type=str, default='PINN_model', help='File name to save the model')\n",
    "        parser.add_argument('--display-freq', type=int, default=1000, help='How often to display loss information')\n",
    "        parser.add_argument('-f')\n",
    "        args = parser.parse_args()\n",
    "\n",
    "        N = 512\n",
    "        h = 2*np.pi/N\n",
    "        nt = 201\n",
    "        beta = 50\n",
    "        \n",
    "        x = np.arange(0, 2*np.pi, h)\n",
    "        t = np.linspace(0, 1, nt).reshape(-1, 1)        \n",
    "        \n",
    "        X, T = np.meshgrid(x,t)\n",
    "        X_star = torch.tensor(np.hstack((X.flatten()[:,None], T.flatten()[:,None])), dtype = torch.float32)\n",
    "        \n",
    "        u0 = function(x)\n",
    "        G = (np.copy(u0)*0)\n",
    "        IKX_pos =1j * np.arange(0, N/2+1, 1)\n",
    "        IKX_neg = 1j * np.arange(-N/2+1, 0, 1)\n",
    "        IKX = np.concatenate((IKX_pos, IKX_neg))\n",
    "        IKX2 = IKX * IKX\n",
    "\n",
    "        uhat0 = np.fft.fft(u0)\n",
    "        nu = 0\n",
    "        nu_factor = np.exp(nu * IKX2 * T - beta * IKX * T)\n",
    "        A = uhat0 - np.fft.fft(G)*0 # at t=0, second term goes away\n",
    "        uhat = A*nu_factor + np.fft.fft(G)*T # for constant, fft(p) dt = fft(p)*T\n",
    "        u = np.real(np.fft.ifft(uhat))\n",
    "\n",
    "        u_star = torch.tensor(u.flatten(), dtype = torch.float32)\n",
    "        Exact_u = (u_star.reshape(201,512)).T\n",
    "        \n",
    "        if not os.path.exists(\"../models/\"):\n",
    "            os.mkdir(\"../models/\")\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        NHiddenLayers = args.layers\n",
    "        \n",
    "        boundaries = [0, 2*torch.pi]\n",
    "        t_domain = [0., 1.]\n",
    "        \n",
    "        Layers = [2] + [args.nodes]*NHiddenLayers + [1]\n",
    "        Activation = nn.Tanh()\n",
    "\n",
    "        k = 1\n",
    "        c = 1\n",
    "\n",
    "        repeat = [0, 1, 2, 3, 4]\n",
    "        for i in repeat:\n",
    "            pinn = PINN(  k = k,\n",
    "                          c = c,\n",
    "                          t= t,\n",
    "                          X_star = X_star,\n",
    "                          u_star = u_star,\n",
    "                          exact_u = Exact_u,\n",
    "                          space_domain = boundaries,\n",
    "                          time_domain = t_domain,\n",
    "                          Layers = Layers,\n",
    "                          N0 = args.N0,\n",
    "                          Nb = args.Nb,\n",
    "                          Nf = args.Nf,\n",
    "                          Activation = Activation,\n",
    "                          device = device,\n",
    "                          model_name = \"../models/\" + args.model_name + \".model_\"+args.method+'_'+str(args.layers)+'_'+str(args.Nf)+'_'+str(i),\n",
    "                          display_freq = args.display_freq, samp = args.method )\n",
    "\n",
    "            Losses_train, Losses_rel_l2 = pinn.Train(args.epochs, weights = (100, 100, 1)) # initial, boundary, residual\n",
    "\n",
    "            torch.save(Losses_train, \"../models/\" + args.model_name + \".loss_\"+args.method+'_'+str(args.layers)+'_'+str(args.Nf)+'_'+str(i))\n",
    "            torch.save(Losses_rel_l2, \"../models/\" + args.model_name + \".rel_l2_\"+args.method+'_'+str(args.layers)+'_'+str(args.Nf)+'_'+str(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
